{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e9a8c1-16a4-47e1-8a36-b1c05bb6d87c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Introduction to Bayesian Models\n",
    "\n",
    "### Goals for today\n",
    "1. Core concepts of Bayesian statistics.\n",
    "2. Interpreting a positive test for a disease.\n",
    "3. Is it a fair coin?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af985b9-f20f-4330-ae0c-f14126cd7265",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# Interpreting a Positive Test for a Disease\n",
    "\n",
    "The base rate fallacy occurs when the base rate (prevalence) of a condition is not taken into account when interpreting diagnostic test results. Let's consider an example:\n",
    "\n",
    "Suppose a disease affects 1% of the population (prevalence). A test for this disease has a:\n",
    "- 99% sensitivity (true positive rate): the probability that the test is positive given that the disease is present.\n",
    "- 95% specificity (true negative rate): the probability that the test is negative given that the disease is not present.\n",
    "\n",
    "Without doing any calculations. Given that a person tests positive, what is the probability that they actually have the disease?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca619bb-07fc-4c7d-9b1c-8d8528141539",
   "metadata": {},
   "source": [
    "**your answer here**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3158edc-f070-4a57-98bf-06228e37fd23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## We need to using Bayesian statistics to answer this properly\n",
    "\n",
    "Bayesian statistics is an approach to statistical inference that uses Bayes' Theorem to combine prior information with data to form our final belief. In this example, we need to consider the prior probability of a disease given our positive test.\n",
    "\n",
    "**Bayes' Theorem**: \n",
    "\n",
    "$$ P(H|E) = \\frac{P(E|H) \\cdot P(H)}{P(E)} $$\n",
    "\n",
    "Where:\n",
    "- $ P(H|E) $ is the posterior probability: the probability of the hypothesis $ H $ given the evidence $ E $.\n",
    "- $ P(E|H) $ is the likelihood: the probability of the evidence $ E $ given that hypothesis $ H $ is true.\n",
    "- $ P(H) $ is the prior probability: the initial probability of the hypothesis before considering the evidence.\n",
    "- $ P(E) $ is the marginal likelihood: the total probability of the evidence under all possible hypotheses.\n",
    "\n",
    "**Keep in mind that \"data\" or \"observations\" are other ways to refer to evidence. The important point is that they all refer to empirical observations, aka, evidence/data/observations.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf8d5e9-5616-4342-8997-77173b3ec406",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 1:\n",
    "\n",
    "Determine how the sensitivity, specificity, and prevalence of a disease fit into Baye's theorem. In other words, which is the prior, likleihood..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b0421d-097b-4000-8534-5dfee236e6e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Your answer here**   \n",
    "\n",
    "Prior: This is the prevalence of the disease in the population. In our example, it's 1% or 0.01.   \n",
    "Likelihood: This is the sensitivity of the test, which is the probability of a positive test result given that the person has the disease. In our example, it's 99% or 0.99.   \n",
    "Posterior probability: This is what we're trying to calculate - the probability that a person has the disease given that they tested positive.   \n",
    "Marginal Likelihood: This is the overall probability of a positive test result.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e2cdd-3708-4435-a685-8edf1b09e0e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 2:   \n",
    "Now that you know how these probabilities fit into Baye's theorem, implement this equation into code and determine what the probability someone has the disease given a positive test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1adce-0988-4269-b078-d6f2a742176b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c6b5a0-7b61-4e89-b521-45b222ce6d9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Practice problem\n",
    "- Calculate the probability of having a disease given the following information:\n",
    "    - The disease effects 0.1% of the population\n",
    "    - The test has a 95% sensitivity rate\n",
    "    - The test has a 92% specificity rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf75aa-96ad-4f9f-b45e-cfc5599dd76d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117baab5-705f-49cd-8b6b-a4afda05b669",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# Determining if a Coin is Fair Using Bayes' Theorem\n",
    "Let's say we want to determine if a coin is a fair coin (has an equal probability of heads vs tails) based on some data we collect with the coin.\n",
    "\n",
    "Suppose you flipped a coin 10 times and got 7 heads and 3 tails. Does this mean the coin isn't fair since we didn't get 5 heads and 5 tails?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0748fb4-99c6-43ab-9981-f9c3057b4f55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Lets define our hypotheses\n",
    "- We want to determine if the coin is fair. \n",
    "- We can collect some data, combine it with our prior knowledge, to come up with an updated belief on the probability of the coin being fair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f57cf3-005f-4fdb-9f78-13e916b95f8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 1\n",
    "- Formulate Bayes' theorem for our problem. In other words, how do we set this up as a Bayesian problem.\n",
    "- What is the Prior? Likelihood? Posterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43f0b2-0ecd-4622-b33f-a837ca7a42d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Your answer here**   \n",
    "Prior: This is our prior belief about the probability of the coin being fair before we observe any data.  \n",
    "Likelihood: This is the probability of observing our data (7 heads and 3 tails in 10 flips) given that the coin is fair.  \n",
    "Posterior: The probability that the coin is fair given our observed data.  \n",
    "Marginal Likelihood: This is the total probability of observing our data under all possible hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1c755-e4b0-4abc-b007-3286af4f78ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### The likelihood\n",
    "- In our case the likelihood is the probability of the data we have observed (7 head out of 10 heads) given our hypothesis $p(D|H)$\n",
    "- Without getting into the details, we can model this as a binomial probability of observing k successes in n trials, using the following equation:\n",
    "$$p(k;n,p) = \\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}$$\n",
    "- Where p is the probability of sucess, k is the observed number of heads, and n is the number of coin flips. The portion on the left-hand side (LHS) can be read as \"the probability of observing k heads (successes), when we have n trials and the coin's probability of coming up heads is p\"\n",
    "- Remember that the likelihood always answers the question \"What is the probability of the data, assuming our hypothesis is true?\". In this case, each tested value of p represents a hypothesis about the fairness of the coin. \n",
    "- Recall that the $!$ represents the factorial. (https://en.wikipedia.org/wiki/Factorial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ba86c-c598-44e1-838a-1ecc39d43adb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 2:\n",
    "- Write a function that implements this equation. It should take in 3 arguments (p,n,k) and return the likelihood. You can import the `math` libary and use `math.factorial(x)` in your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c8c20-4fcc-4b50-9860-d03395c745a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your answer here\n",
    "# First, import\n",
    "from math import factorial\n",
    "\n",
    "# Write your function below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba113b-fc7c-4372-8a62-510f3f759aa6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 3: Building the likelihood function\n",
    "- Now that we have a way of calculating our probabilities you can build your likelihood function.\n",
    "- Keeping the number of coin flips and heads constant, iterate through the different possible values of p and calculate the likelihood for each. \n",
    "- Plot this is a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2244430-83d7-40dd-9ef9-9f00ba1cd978",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7042405b-6258-4d4c-a39c-39f4c3679920",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 4:\n",
    "- Now we have the likelihood, we can use Baye's rule to calculate the posterior.\n",
    "- For this task, we will start with a uniform prior. You can use the function `np.ones_like()`\n",
    "- Write code to calculate the posterior distribution, given a uniform prior and the likelihood you have made above.\n",
    "- Luckily, you don't always have to calculate the marginal likelihood. Since we know that all discrete probability distributions must sum to 1, we can normalize distribution as a last step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72be2dc-298d-4d30-886a-0792bf8facf9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2703b409-c6c1-48f3-818c-d0e5d9813be6",
   "metadata": {},
   "source": [
    "## Think!\n",
    "\n",
    "If it seems confusing that the x-axis and y-axis labels both refer to probabilities, that just means you've been paying attention. While it may seem odd, keep in mind that the $p$ quantified on the x-axis refers to the underlying probability that your coin (in technical terms, a \"Bernoulli process\") comes up heads (or 1, or \"success\"). Meanwhile, the probability on the y-axis refers to the probability that $p$ takes on its respective value. In other words, we're computing the probability that a coin's probability of coming up heads is whatever the x-axis value is. If we're dealing with a perfectly fair coin, then the y-axis values will be greatest around 0.5. If the coin is a trick coin that always comes up tails, then most of the probability will cluster around $p=0$. Depending on the amount of data we collect and our priors, the clustering around 0.5 (or 0, in the second example) will be more concentrated or more diffuse (i.e., spread out).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aeaa47-2544-4d27-b1fc-e3ef7254b366",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 5:\n",
    "- Create a function to calculate the posterior. It should take in a prior distribution, p, n, and k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fffba1-16ad-4644-a929-8ac0364386d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a3989a5-bc05-47dc-b64a-f2f20026d5bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 6:\n",
    "- What happens if we get 10 head out of 16 coin flips?\n",
    "- Create a figure that shows the prior (uniform), likelihood, and the posterior for this situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443d9e8-9e77-4b48-be17-3c804cb94b0f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22039b52-cb27-4f1a-8502-5c31e5546331",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 7:\n",
    "- Previously, we have only looked at what happens when we use a uniform prior. Now we will see what happens when we use a non-uniform prior.\n",
    "- Without getting into the mathematics, we can use a Beta distribution as our prior.\n",
    "- For simplicity, we will just import a function to generate this distribution from the scipy library (See example below). The beta distribution takes two parameters, referred to as \"shape\" parameters\n",
    "- First, plot the beta distribution with the values of 10 and 10.\n",
    "- Next, repeat task 6 with this new prior distribution. How does this change our posterior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e6b2f-abb4-4931-9599-a3812dbe1ec1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta # Needed for this section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef86323-7a0d-48b1-876e-b63d13d7cad8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7c87a-e518-4d19-9aa2-343f8e811b56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 8:\n",
    "- Using the beta distribution, if you keep the two parameters the same, the distribution will remain symmetric centered at 0.5. If you increase both parameters, the distribution will become narrower (stronger prior) or if you lower them it becomes wider (weaker prior).\n",
    "- Play around with changing the strength of the prior and look at how this changes the posterior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
