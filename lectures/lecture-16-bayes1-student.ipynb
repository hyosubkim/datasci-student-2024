{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e9a8c1-16a4-47e1-8a36-b1c05bb6d87c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Introduction to Bayesian Models\n",
    "\n",
    "### Goals for today\n",
    "1. Core concepts of Bayesian statistics.\n",
    "2. Interpreting a positive test for a disease.\n",
    "3. Answer the question: Is it a fair coin?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af985b9-f20f-4330-ae0c-f14126cd7265",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# Interpreting a Positive Test for a Disease\n",
    "\n",
    "The base rate fallacy occurs when the base rate (prevalence) of a condition is not taken into account when interpreting diagnostic test results. Let's consider an example:\n",
    "\n",
    "Suppose a disease affects 1% of the population (prevalence). A test for this disease has a:\n",
    "- 99% sensitivity (true positive rate): the probability that the test is positive given that the disease is present.\n",
    "- 95% specificity (true negative rate): the probability that the test is negative given that the disease is not present.\n",
    "\n",
    "Without doing any calculations. Given that a person tests positive, what is the probability that they actually have the disease?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca619bb-07fc-4c7d-9b1c-8d8528141539",
   "metadata": {},
   "source": [
    "**your answer here**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3158edc-f070-4a57-98bf-06228e37fd23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## We need to using Bayesian statistics to answer this properly\n",
    "\n",
    "Bayesian statistics is an approach to statistical inference that uses Bayes' Theorem to combine prior information with data to form our final belief. In this example, we need to consider the prior probability of a disease given our positive test.\n",
    "\n",
    "**Bayes' Theorem**: \n",
    "\n",
    "$$ P(H|E) = \\frac{P(E|H) \\cdot P(H)}{P(E)} $$\n",
    "\n",
    "Where:\n",
    "- $ P(H|E) $ is the posterior probability: the probability of the hypothesis $ H $ given the evidence $ E $.\n",
    "- $ P(E|H) $ is the likelihood: the probability of the evidence $ E $ given that hypothesis $ H $ is true.\n",
    "- $ P(H) $ is the prior probability: the initial probability of the hypothesis before considering the evidence.\n",
    "- $ P(E) $ is the marginal likelihood: the total probability of the evidence under all possible hypotheses.\n",
    "\n",
    "**Keep in mind that \"data\" or \"observations\" are other ways to refer to evidence. The important point is that they all refer to empirical observations, aka, evidence/data/observations.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf8d5e9-5616-4342-8997-77173b3ec406",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 1:\n",
    "\n",
    "Determine how the sensitivity, specificity, and prevalence of a disease fit into Bayes' theorem. In other words, which is the prior, likelihood..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b0421d-097b-4000-8534-5dfee236e6e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Your answer here**   \n",
    "\n",
    "Prior: This is the prevalence of the disease in the population. In our example, it's 1% or 0.01.   \n",
    "Likelihood: This is the sensitivity of the test, which is the probability of a positive test result given that the person has the disease. In our example, it's 99% or 0.99.   \n",
    "Posterior probability: This is what we're trying to calculate - the probability that a person has the disease given that they tested positive.   \n",
    "Marginal Likelihood: This is the overall probability of a positive test result.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e2cdd-3708-4435-a685-8edf1b09e0e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 2:   \n",
    "Now that you know how these probabilities fit into Bayes' theorem, implement this equation into code and determine what the probability someone has the disease given a positive test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1adce-0988-4269-b078-d6f2a742176b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your answer here\n",
    "\n",
    "# Parameters\n",
    "prevalence = 0.01   # 1% prevalence\n",
    "sensitivity = 0.99  # 99% sensitivity\n",
    "specificity = 0.95  # 95% specificity\n",
    "\n",
    "# Calculate the false positive rate\n",
    "false_positive_rate = 1 - specificity\n",
    "\n",
    "# Calculate the total probability of a positive test\n",
    "p_positive = prevalence * sensitivity + (1 - prevalence) * false_positive_rate\n",
    "\n",
    "# Calculate the posterior probability using Bayes' Theorem\n",
    "p_disease_given_positive = (sensitivity * prevalence) / p_positive\n",
    "\n",
    "print(f\"Given a positive test result, the probability of having the disease is {p_disease_given_positive:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c6b5a0-7b61-4e89-b521-45b222ce6d9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Practice problem\n",
    "- Calculate the probability of having a disease given the following information:\n",
    "    - The disease affects 0.1% of the population\n",
    "    - The test has a 95% sensitivity rate\n",
    "    - The test has a 92% specificity rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf75aa-96ad-4f9f-b45e-cfc5599dd76d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your answer here\n",
    "# Parameters\n",
    "prior = 0.001  # 0.1% prevalence\n",
    "p_pos_disease = 0.95  # 95% sensitivity\n",
    "p_neg_nodisease = 0.92  # 92% specificity\n",
    "\n",
    "# Calculate the false positive rate\n",
    "p_pos_nodisease = 1 - p_neg_nodisease\n",
    "\n",
    "# Calculate the total probability of a positive test\n",
    "p_pos = prior * p_pos_disease + (1 - prior) * p_pos_nodisease\n",
    "\n",
    "# Calculate the posterior probability using Bayes' Theorem\n",
    "p_disease_given_positive = (prior * p_pos_disease) / p_pos\n",
    "\n",
    "print(f\"Given a positive test result, the probability of having the disease is {p_disease_given_positive:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117baab5-705f-49cd-8b6b-a4afda05b669",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# Determining if a Coin is Fair Using Bayes' Theorem\n",
    "Let's say we want to determine if a coin is a fair coin (has an equal probability of heads vs tails) based on some data we collect with the coin.\n",
    "\n",
    "Suppose you flipped a coin 10 times and got 7 heads and 3 tails. Does this mean the coin isn't fair since we didn't get 5 heads and 5 tails?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0748fb4-99c6-43ab-9981-f9c3057b4f55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Lets define our hypotheses\n",
    "- We want to determine if the coin is fair. \n",
    "- We can collect some data, combine it with our prior knowledge, to come up with an updated belief on the probability of the coin being fair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f57cf3-005f-4fdb-9f78-13e916b95f8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 1\n",
    "- Formulate Bayes' theorem for our problem. In other words, how do we set this up as a Bayesian problem.\n",
    "- What is the Prior? Likelihood? Posterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43f0b2-0ecd-4622-b33f-a837ca7a42d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Your answer here**   \n",
    "Prior: This is our prior belief about the probability of the coin being fair before we observe any data.  \n",
    "Likelihood: This is the probability of observing our data (7 heads and 3 tails in 10 flips) given that the coin is fair.  \n",
    "Posterior: The probability that the coin is fair given our observed data.  \n",
    "Marginal Likelihood: This is the total probability of observing our data under all possible hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1c755-e4b0-4abc-b007-3286af4f78ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### The likelihood\n",
    "- In our case the likelihood is the probability of the data we have observed (7 head out of 10 heads) given our hypothesis $p(D|H)$\n",
    "- Without getting into the details, we can model this as a binomial probability of observing k successes in n trials, using the following equation:\n",
    "$$p(k;n,p) = \\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}$$\n",
    "- Where p is the probability of sucess, k is the observed number of heads, and n is the number of coin flips. The portion on the left-hand side (LHS) can be read as \"the probability of observing k heads (successes), when we have n trials and the coin's probability of coming up heads is p\"\n",
    "- Remember that the likelihood always answers the question \"What is the probability of the data, assuming our hypothesis is true?\". In this case, each tested value of p represents a hypothesis about the fairness of the coin. \n",
    "- Recall that the $!$ represents the factorial. (https://en.wikipedia.org/wiki/Factorial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ba86c-c598-44e1-838a-1ecc39d43adb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 2:\n",
    "- Write a function that implements this equation. It should take in 3 arguments (p,n,k) and return the likelihood. You can import the `math` libary and use `math.factorial(x)` in your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c8c20-4fcc-4b50-9860-d03395c745a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your answer here\n",
    "from math import factorial\n",
    "\n",
    "def binomial_probability(p, n, k):\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba113b-fc7c-4372-8a62-510f3f759aa6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 3: Building the likelihood function\n",
    "- Now that we have a way of calculating our probabilities you can build your likelihood function.\n",
    "- Keeping the number of coin flips and heads constant, iterate through the different possible values of p (test 100 different values of p&mdash;i.e., hypotheses&mdash;from 0 through 1) and calculate the likelihood for each. \n",
    "- Plot this as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2244430-83d7-40dd-9ef9-9f00ba1cd978",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n_trials = 10\n",
    "n_heads = 7\n",
    "\n",
    "p_values = np.linspace(0, 1, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7042405b-6258-4d4c-a39c-39f4c3679920",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 4:\n",
    "- Now we have the likelihood, we can use Bayes' rule to calculate the posterior.\n",
    "- For this task, we will start with a uniform prior. You can use the function `np.ones_like()`\n",
    "- Write code to calculate the posterior distribution, given a uniform prior and the likelihood you have made above.\n",
    "- Luckily, you don't always have to calculate the marginal likelihood. Since we know that all discrete probability distributions must sum to 1, we can normalize our distribution as a last step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72be2dc-298d-4d30-886a-0792bf8facf9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prior (uniform in this case)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703b409-c6c1-48f3-818c-d0e5d9813be6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Think!\n",
    "\n",
    "If it seems confusing that the x-axis and y-axis labels both refer to probabilities, that just means you've been paying attention. While it may seem odd, keep in mind that the $p$ quantified on the x-axis refers to the underlying probability that your coin (in technical terms, a \"Bernoulli process\") comes up heads (or 1, or \"success\"). Meanwhile, the probability on the y-axis refers to the probability that $p$ takes on its respective value. In other words, we're computing the probability that a coin's probability of coming up heads is whatever the x-axis value is. If we're dealing with a perfectly fair coin, then the y-axis values will be greatest around 0.5. If the coin is a trick coin that always comes up tails, then most of the probability will cluster around $p=0$. Depending on the amount of data we collect and our priors, the clustering around 0.5 (or 0, in the second example) will be more concentrated or more diffuse (i.e., spread out).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aeaa47-2544-4d27-b1fc-e3ef7254b366",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 5:\n",
    "- Create a function to calculate the posterior. It should take in a prior distribution, p, n, and k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fffba1-16ad-4644-a929-8ac0364386d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_posterior(p_values, n, k, prior):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3989a5-bc05-47dc-b64a-f2f20026d5bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 6:\n",
    "- What happens if we get 10 heads out of 16 coin flips?\n",
    "- Create a figure that shows the prior (uniform), likelihood, and the posterior for this situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443d9e8-9e77-4b48-be17-3c804cb94b0f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate p values from 0 to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22039b52-cb27-4f1a-8502-5c31e5546331",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 7:\n",
    "- Previously, we have only looked at what happens when we use a uniform prior. Now we will see what happens when we use a non-uniform prior.\n",
    "- Without getting into the mathematics, we can use a Beta distribution as our prior.\n",
    "- For simplicity, we will just import a function to generate this distribution from the scipy library (See example below). The beta distribution takes two parameters, referred to as \"shape\" parameters\n",
    "- First, plot the beta distribution with the values of 10 and 10.\n",
    "- Next, repeat task 6 with this new prior distribution. How does this change our posterior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e6b2f-abb4-4931-9599-a3812dbe1ec1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta # Needed for this section\n",
    "\n",
    "p_values = np.linspace(0, 1, 1000)\n",
    "beta_prior = beta.pdf(p_values, 10, 10)  \n",
    "\n",
    "# Plot your prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef86323-7a0d-48b1-876e-b63d13d7cad8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# Generate p values from 0 to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7c87a-e518-4d19-9aa2-343f8e811b56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 8:\n",
    "- Using the beta distribution, if you keep the two parameters the same, the distribution will remain symmetric centered at 0.5. If you increase both parameters, the distribution will become narrower (stronger prior) or if you lower them it becomes wider (weaker prior).\n",
    "- Play around with changing the strength of the prior and look at how this changes the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4169910e-a915-49c5-9227-95597ccee901",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b379b1-cbb6-4957-989b-6281925e5c3e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### Task 9: See how having lots of data can outweigh even a highly (over)confident prior.\n",
    "\n",
    "We are in a toy shop that makes trick coins where the probability of heads is roughly 0.32. We pick up a random coin off the ground of the shop and assume it's one of the trick coins, although we can't be positive. To be sure one way or the other, we flip the coin 400 times (we have lots of free time on our hands) and record the number of heads. \n",
    "\n",
    "- Use beta shape parameters of 10 and 20 and simulate 200 heads out of 400 coin flips\n",
    "- Interpret the prior, likelihood, and posterior?\n",
    "- Read out the most probable value of $p$ according to each?\n",
    "- Is it a fair or trick coin? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f448416-09a3-43f9-9700-c6b344b05625",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Generate p values from 0 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ba44a-9db6-4fa2-881b-31d64e283ac4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read out probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28202fc-21fb-4726-b439-56a0d0c074df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Take-aways\n",
    "\n",
    "**Bayesian statistics:**\n",
    "- Provides the correct means to quantify the plausibility of a hypothesis or set of hypotheses\n",
    "- Requires defining prior probabilities, $p(H)$, and likelihoods, $p(D|H)$.\n",
    "- Sometimes requires computing $p(D)$, which can get tricky, but frequently you can bypass this step by normalization\n",
    "- Makes clear that an abundance of high-quality data will outweigh an incorrectly biased prior&mdash;as it should!\n",
    "- Has powerful applications in nearly all branches of science: neuroscience, kinesiology, economics, psychology, climatology...\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
